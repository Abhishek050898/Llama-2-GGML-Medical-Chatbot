# ğŸ¥ Llama-2-GGML Medical Chatbot ğŸš€

A **Retrieval-Augmented Generation (RAG) based chatbot** that leverages **Llama-2-GGML** and **FAISS** to provide responses to medical-related queries by searching within **medical PDFs**. The chatbot is powered by **LangChain**, **FAISS vector search**, and a **Streamlit UI**.

---

## ğŸ“Œ Features
âœ… **Retrieval-Augmented Generation (RAG)** - Uses FAISS to search medical PDFs.  
âœ… **Llama-2-GGML Model** - Runs locally for private medical Q&A.  
âœ… **Streamlit UI** - User-friendly web-based chatbot interface.  
âœ… **PDF Knowledge Base** - Users can upload medical PDFs to expand chatbot knowledge.  
âœ… **Docker Support** - Easily deployable using **Docker**.  

---

## ğŸ“‚ Project Structure
```
ğŸ“ Llama-2-GGML-Medical-Chatbot
â”‚â”€â”€ ğŸ“„ model.py          # Chatbot logic (LangChain RAG + Streamlit UI)
â”‚â”€â”€ ğŸ“„ vector.py         # PDF processing & FAISS vector store creation
â”‚â”€â”€ ğŸ“„ Dockerfile        # Containerization instructions
â”‚â”€â”€ ğŸ“„ requirements.txt  # Required Python libraries
â”‚â”€â”€ ğŸ“ vectorstores/     # FAISS database for PDF storage
â”‚â”€â”€ ğŸ“ data/             # Medical PDFs (for indexing)
â”‚â”€â”€ ğŸ“ assets/           # UI assets (logos, images)
â”‚â”€â”€ ğŸ“„ README.md         # Documentation (You are here)
```

---

## ğŸ›  Installation
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/Llama-2-GGML-Medical-Chatbot.git
cd Llama-2-GGML-Medical-Chatbot
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Build the FAISS Vector Store
Before running the chatbot, **index the PDFs**:
```bash
python vector.py
```
ğŸ”¹ This extracts text from PDFs and stores embeddings in **FAISS**.

### 4ï¸âƒ£ Run the Chatbot
```bash
streamlit run model.py
```
ğŸ”¹ Open your browser and go to ğŸ‘‰ **`http://localhost:8501`**

---

## ğŸ“¦ Running with Docker
### 1ï¸âƒ£ Build the Docker Image
```bash
docker build -t medical-chatbot .
```

### 2ï¸âƒ£ Run the Docker Container
```bash
docker run -p 8501:8501 medical-chatbot
```
ğŸ”¹ Access the chatbot at ğŸ‘‰ **`http://localhost:8501`**



## ğŸ” How It Works
### 1ï¸âƒ£ Process Medical PDFs
- **Extracts medical knowledge** using `vector.py` (FAISS indexing).
- Stores **vector embeddings** for **fast retrieval**.

### 2ï¸âƒ£ Ask Questions
- The chatbot **retrieves relevant content** from indexed PDFs.
- **Llama-2-GGML** generates a **human-like response**.

### 3ï¸âƒ£ Retrieve from FAISS
- If **no relevant data is found**, it informs the user instead of hallucinating.

---

## âš¡ Technologies Used
ğŸ”¹ **Llama-2-GGML** - Open-source LLM optimized for fast CPU inference.  
ğŸ”¹ **LangChain** - Used for document retrieval and response generation.  
ğŸ”¹ **FAISS** - Vector search database for PDF embeddings.  
ğŸ”¹ **Streamlit** - Web UI framework for chatbot interaction.  
ğŸ”¹ **Docker** - Containerized environment for easy deployment.  

---

![Llama-2 Medical Chatbot](assets/chatbot.png)


## ğŸ¤– Example Usage
### 1ï¸âƒ£ Upload a Medical PDF
- Upload **The Gale Encyclopedia of Medicine** or other documents.
- The system **processes** and **indexes** the content.

### 2ï¸âƒ£ Ask a Medical Question
ğŸ’¬ **Example:**
```
User: What are the symptoms of diabetes?
```

ğŸ¤– **Response:**
```
The symptoms of diabetes include frequent urination, increased thirst, fatigue, blurred vision, unintended weight loss, and slow healing of wounds.
```



## ğŸ“œ License
MIT License - Free to use and modify.

---

## ğŸ¤ Contributing
Want to improve this chatbot? Feel free to:
1. Fork the repo
2. Create a feature branch
3. Submit a pull request ğŸš€

---

